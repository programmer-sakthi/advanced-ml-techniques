Problem Statement



A company wants to predict the "average monthly hours" an employee works using relevant features from their workplace data. This prediction is crucial for the HR team to identify early warning signs of burnout, overwork, or disengagement among employees. By applying a regression model, HR can gain actionable insights to support employee well-being, maintain healthy work-life balance, and improve overall productivity across the organization.



The first critical step in building this predictive regression model is Data Preparation for Regression Modeling. This involves selecting the appropriate features (independent variables) that can effectively predict the target variable, and preparing the data through proper scaling and transformation techniques.



The data scientist needs to:



Import and explore the dataset – Load the preprocessed employee data that already contains encoded categorical variables, examine its structure, data types, and statistical properties to understand the available features.


Select relevant features – Identify and extract the most appropriate input features (independent variables) from the dataset that will be used to predict average monthly hours. This requires excluding the target variable itself and removing any irrelevant or non-predictive columns.


Identify the target variable – Clearly define the target variable (dependent variable) that the regression model will predict, which in this case is the average monthly hours worked by employees.


Scale the features – Apply feature scaling using StandardScaler to normalize the input features. This is essential for regression models as it ensures all features contribute equally to the model regardless of their original scales, improving model performance and convergence.


This data preparation phase ensures that the dataset is properly structured and transformed for building an effective regression model. The output will provide a clean separation between features and target, with appropriately scaled input data ready for model training.



CSV File Structure



﻿



Sample Data



satisfaction_level,last_evaluation,number_project,average_monthly_hours,time_spend_company,Work_accident,left,promotion_last_5years,Department,salary,salary.enc,Department.enc

0.38,0.53,2,157,3,0,1,0,sales,low,1,7

0.8,0.86,5,262,6,0,1,0,sales,medium,2,7

0.11,0.88,7,272,4,0,1,0,sales,medium,2,7

0.72,0.87,5,223,5,0,1,0,sales,low,1,7

0.37,0.52,2,159,3,0,1,0,sales,low,1,7

Input format :
CSV File Input:

The program prompts the user to enter the name of the CSV file containing employee data.
Input must include the file extension .csv.
Output format :
The program generates the following outputs in sequence:



1. Number of Samples:



Prints: "The number of samples in data is X." where X is the total number of rows in the dataset


2. Data Types:



Prints a blank line followed by: Data Types:
Lists all column names with their corresponding data types
Shows each column on a new line in the format: column_name dtype
Ends with dtype: object


3. Numeric Summary:



Prints a blank line followed by: Numeric Summary:
Displays statistical summary using .describe() method
Shows count, mean, std, min, 25%, 50%, 75%, max for all numeric columns
Includes dimension summary: [8 rows x N columns] where N is the number of numeric columns


4. Data After Dropping Irrelevant Columns:



Prints a blank line followed by: Data After Dropping Irrelevant Columns:
Displays DataFrame information using .info() method showing:
DataFrame class type: <class 'pandas.core.frame.DataFrame'>
Index range: RangeIndex: X entries, 0 to Y
Total number of columns (10 columns) with non-null counts and data types
Each column listed with format: # Column Non-Null Count Dtype
Data types breakdown (e.g., float64(2), int64(8))
Memory usage information
Ends with None (output of .info() method)


5. Input Features:



Prints a blank line followed by: Input Features:
Displays the first 5 rows of the feature DataFrame (all columns except target variable)
Shows in tabular format with column names and row indices
Includes dimension summary: [5 rows x 9 columns] (9 features after excluding target)


6. Target Variable:



Prints a blank line followed by: Target Variable:
Displays the first 5 values of the target variable (average_monthly_hours)
Shows row indices (0-4) with corresponding target values
Ends with: Name: average_monthly_hours, dtype: int64


7. Scaled Feature Data:



Prints a blank line followed by: Scaled Feature Data:
Displays the first 5 rows of the scaled feature DataFrame
Values are standardized (z-score normalization) with mean=0 and std=1
Shows in tabular format with same column names as input features
Includes dimension summary: [5 rows x 9 columns]


Refer to the sample output for exact formatting specifications.

Code constraints :
CSV File Constraints



File must be a comma-separated CSV file with .csv extension
File must exist in the same directory as the Python script
File must contain exactly 12 columns with the following exact column names (case-sensitive): satisfaction_level, last_evaluation, number_project, average_monthly_hours, time_spend_company, Work_accident, left, promotion_last_5years, Department, salary, salary.enc, Department.enc
Column order must match the specified structure
The CSV file should contain preprocessed data with both original categorical columns (Department, salary) and their encoded versions (Department.enc, salary.enc)


Column Data Type Constraints



satisfaction_level, last_evaluation → float
number_project, average_monthly_hours, time_spend_company → integer
Work_accident, left, promotion_last_5years → integer (0/1)
Department, salary → string
salary.enc, Department.enc → integer


Feature Selection Constraints



Target Variable: average_monthly_hours is the dependent variable to be predicted
Features to Drop: The original categorical text columns Department and salary must be removed before model training as they have been replaced by their encoded counterparts
Input Features: All remaining columns except the target variable constitute the feature set


Data Scaling Constraints



Scaling Method: StandardScaler is used for feature normalization
Scaling Application: Scaling is applied only to numeric columns in the feature set
Scaling Formula: Each feature is transformed using z-score normalization: (x - mean) / standard_deviation
Result: Scaled features have mean ≈ 0 and standard deviation ≈ 1
Column Preservation: Scaled DataFrame maintains the same column names as the original feature DataFrame


Program Processing Constraints



If the CSV file is not found, the program prints: Error: File '{filename}' not found. and exits
The Department and salary columns are dropped before feature selection to avoid using redundant non-encoded categorical data
The feature DataFrame (input_df) contains all columns except average_monthly_hours
The target DataFrame (output_df) contains only the average_monthly_hours column
The scaling operation uses the data_scale() function from the ML_Modules.py module
The final scaled feature DataFrame contains 9 columns (all numeric features after dropping categorical text columns and target)


ML_Modules.py Requirements



The ML_Modules.py file must be present in the same directory as main.py
The module must contain a data_scale(X_DT) function that:
Accepts a pandas DataFrame as input
Selects only numeric columns using .select_dtypes(include='number')
Applies StandardScaler from sklearn.preprocessing
Returns a scaled pandas DataFrame with the same column names
Sample test cases :
Input 1 :
Sample.csv
Output 1 :
The number of samples in data is 50.

Data Types:
satisfaction_level       float64
last_evaluation          float64
number_project             int64
average_monthly_hours      int64
time_spend_company         int64
Work_accident              int64
left                       int64
promotion_last_5years      int64
Department                object
salary                    object
salary.enc                 int64
Department.enc             int64
dtype: object

Numeric Summary:
       satisfaction_level  last_evaluation  ...  salary.enc  Department.enc
count           50.000000        50.000000  ...   50.000000       50.000000
mean             0.453800         0.676000  ...    1.040000        6.900000
std              0.250387         0.181816  ...    0.197949        1.950929
min              0.090000         0.460000  ...    1.000000        2.000000
25%              0.380000         0.530000  ...    1.000000        7.000000
50%              0.410000         0.565000  ...    1.000000        7.000000
75%              0.542500         0.870000  ...    1.000000        8.000000
max              0.920000         1.000000  ...    2.000000        9.000000

[8 rows x 10 columns]

Data After Dropping Irrelevant Columns:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 50 entries, 0 to 49
Data columns (total 10 columns):
 #   Column                 Non-Null Count  Dtype  
---  ------                 --------------  -----  
 0   satisfaction_level     50 non-null     float64
 1   last_evaluation        50 non-null     float64
 2   number_project         50 non-null     int64  
 3   average_monthly_hours  50 non-null     int64  
 4   time_spend_company     50 non-null     int64  
 5   Work_accident          50 non-null     int64  
 6   left                   50 non-null     int64  
 7   promotion_last_5years  50 non-null     int64  
 8   salary.enc             50 non-null     int64  
 9   Department.enc         50 non-null     int64  
dtypes: float64(2), int64(8)
memory usage: 4.0 KB
None

Input Features:
   satisfaction_level  last_evaluation  ...  salary.enc  Department.enc
0                0.38             0.53  ...           1               7
1                0.80             0.86  ...           2               7
2                0.11             0.88  ...           2               7
3                0.72             0.87  ...           1               7
4                0.37             0.52  ...           1               7

[5 rows x 9 columns]

Target Variable:
0    157
1    262
2    272
3    223
4    159
Name: average_monthly_hours, dtype: int64

Scaled Feature Data:
   satisfaction_level  last_evaluation  ...  salary.enc  Department.enc
0           -0.297737        -0.811161  ...   -0.204124        0.051778
1            1.396700         1.022285  ...    4.898979        0.051778
2           -1.387017         1.133403  ...    4.898979        0.051778
3            1.073950         1.077844  ...   -0.204124        0.051778
4           -0.338080        -0.866720  ...   -0.204124        0.051778

[5 rows x 9 columns]