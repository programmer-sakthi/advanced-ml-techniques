Problem Statement



To maximize the effectiveness of employee attrition prediction, the company's data science team needs to optimize the SVM model through hyperparameter tuning. While the baseline SVM model provides initial predictions, its performance can be significantly improved by systematically searching for the optimal combination of model parameters.



Hyperparameter tuning is a critical step in machine learning that involves finding the best configuration of model parameters to achieve optimal performance. Unlike model parameters that are learned during training (like support vectors), hyperparameters are set before training and control the learning process itself.



For SVM classification, key hyperparameters include:



C (Regularization parameter) – Controls the trade-off between achieving a low training error and maintaining a simple decision boundary. Higher C values create more complex models that fit training data closely, while lower C values create simpler, more generalizable models.


Gamma (Kernel coefficient) – Defines how far the influence of a single training example reaches. Low gamma means far reach (smoother decision boundary), while high gamma means close reach (more complex boundary).


Kernel type – Determines the type of transformation applied to make data separable (linear, polynomial, RBF, sigmoid).


The objective of this task is to:



	1. Perform comprehensive data preprocessing – The main script must handle all preprocessing independently, including loading the CSV file, encoding categorical variables, separating features from labels, and scaling data to prepare for model training.



	2. Implement Grid Search with Cross-Validation – Use GridSearchCV with 5-fold cross-validation to systematically test multiple combinations of hyperparameters. This technique divides the training data into 5 subsets, trains the model on 4 subsets, validates on the remaining subset, and rotates this process 5 times to ensure robust parameter selection.



	3. Train optimized SVM model – Apply the best hyperparameters discovered through grid search to train a final SVM classifier that balances bias (underfitting) and variance (overfitting) effectively.



	4. Evaluate and compare performance – Assess the tuned model's performance using comprehensive metrics and compare results with the baseline model to determine the improvement achieved through hyperparameter optimization.



This task demonstrates the importance of systematic parameter optimization in building production-ready machine learning models that generalize well to unseen data.



CSV File Structure



﻿



Sample Data



satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company,Work_accident,left,promotion_last_5years,Department,salary

0.45,0.56,2,154,3,0,1,0,marketing,low

0.37,0.52,2,143,3,0,0,0,marketing,low

0.4,0.52,2,155,3,0,1,0,marketing,low

0.39,0.48,2,160,3,0,0,0,sales,low

0.11,0.8,6,304,4,0,1,0,accounting,low

Input format :
CSV File Input:

The program prompts the user to enter the name of the CSV file containing employee data.
Input must include the file extension .csv.
Output format :
The program produces the following evaluation outputs:



1. Confusion Matrix:



Prints the heading: Confusion Matrix
Displays a 2×2 matrix showing the classification results:
[[TN FP]

[FN TP]]

Where:
TN (True Negative) = Correctly predicted as "Not Left" (class 0)
FP (False Positive) = Incorrectly predicted as "Left" (class 1) when actually "Not Left"
FN (False Negative) = Incorrectly predicted as "Not Left" when actually "Left"
TP (True Positive) = Correctly predicted as "Left" (class 1)
Followed by: =================== (separator line)


2. Classification Report:



Prints a blank line followed by: Classification Report:
Displays a detailed classification report with 3 decimal places showing:
Per-class metrics (for class 0 and class 1):
precision – Ratio of correct positive predictions to total positive predictions
recall – Ratio of correct positive predictions to total actual positives
f1-score – Harmonic mean of precision and recall
support – Number of actual occurrences of each class in the test set


Overall metrics:
accuracy – Overall correctness of predictions
macro avg – Unweighted average of per-class metrics
weighted avg – Weighted average of per-class metrics (weighted by support)
Format includes proper column alignment with decimal values rounded to 3 places
Followed by: =================== (separator line)


3. Individual Metrics:



Four individual metrics, each on a separate line:
accuracy: X.XXX – Overall accuracy score (3 decimal places)
recall: X.XXX – Recall score for class 1 (3 decimal places)
f1-score: X.XXX – F1-score for class 1 (3 decimal places)
precision: X.XXX – Precision score for class 1 (3 decimal places)
All metrics are rounded to exactly 3 decimal places
Format: metric_name: value (lowercase metric name, colon, space, value)


Note: The output contains NO intermediate printing during data loading, encoding, scaling, splitting, or grid search. Only the final evaluation metrics for the tuned model are displayed.



Refer to the sample output for exact formatting specifications.

Code constraints :
CSV File Requirements



File must be a comma-separated .csv and located in the same directory as main.py and ML_Modules.py.
Must contain exactly the following 10 columns (case-sensitive): satisfaction_level, last_evaluation, number_project, average_montly_hours, time_spend_company, Work_accident, left, promotion_last_5years, Department, salary
Minimum 15 data rows (excluding header).
left column must contain 0/1 values (target label).
No missing values allowed.
Numeric columns must contain valid numeric values.
Department and salary must contain categorical values that can be label encoded.


Preprocessing Constraints



Categorical Encoding



Encode salary → salary.enc using LabelEncoder (alphabetical class sorting).
Encode Department → Department.enc using LabelEncoder.
Drop original categorical columns (salary, Department) after encoding.


Feature–Label Split



Feature matrix X includes all columns except left.
Label vector y contains only the left column.


Scaling



Use only the function data_scale() from ML_Modules.py.
Must use StandardScaler.
No printing in this function.


Train–Test Split



Use train_test_split with:
test_size = 0.20
random_state = 42
Split must be applied after scaling.


Hyperparameter Tuning Requirements



GridSearchCV Setup
Base estimator: SVC()
Parameter grid:
C: [0.1, 1, 10, 100]
gamma: ['scale', 'auto', 0.01, 0.1, 1]
kernel: ['rbf']
Total combinations = 20
Must use:
cv = 5 (5-fold cross-validation)
scoring = 'accuracy'
n_jobs = -1
No printing of best parameters.
Best Model
Use best_estimator_ to predict on the test set.


Evaluation Rules



Use only evaluate_classifier() in ML_Modules.py, which must:
Print Confusion Matrix
Print Classification Report (digits=3)
Print accuracy, recall, f1-score, precision for class 1
All metric values must be printed with exactly 3 decimal places
No other messages printed anywhere in the pipeline


Error Handling



If file not found → print: Error: File '{filename}' not found.
Sample test cases :
Input 1 :
Sample.csv
Output 1 :
Confusion Matrix
[[2 4]
 [2 2]]
===================

Classification Report:
              precision    recall  f1-score   support

           0      0.500     0.333     0.400         6
           1      0.333     0.500     0.400         4

    accuracy                          0.400        10
   macro avg      0.417     0.417     0.400        10
weighted avg      0.433     0.400     0.400        10

===================
accuracy: 0.400
recall: 0.500
f1-score: 0.400
precision: 0.333