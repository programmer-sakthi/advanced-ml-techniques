Problem Statement



Building upon the diabetes detection system, the data science team now aims to optimize the SVM model's performance through systematic hyperparameter tuning. While a baseline SVM model can provide initial predictions, its effectiveness can be significantly enhanced by finding the optimal combination of model parameters that maximize classification accuracy.



Hyperparameter optimization is crucial for developing production-ready machine learning models. Unlike learned parameters (such as support vectors), hyperparameters control the learning algorithm itself and must be set before training. For medical diagnosis systems like diabetes detection, even small improvements in accuracy can have significant clinical impact, potentially leading to better patient outcomes through earlier and more accurate disease detection.



This task involves:



1. Complete Data Preprocessing Pipeline: Even though the main focus is hyperparameter tuning, the model requires properly preprocessed data. The main script must independently perform all preprocessing steps including:

Loading the csv file
Selecting relevant clinical features for modeling
Removing invalid zero values in critical measurements
Treating outliers using IQR winsorization
Standardizing features through scaling
Splitting data into training and testing sets


2. Systematic Hyperparameter Search: Implement Grid Search with 5-fold cross-validation to explore multiple combinations of SVM hyperparameters:



C (Regularization parameter) – Controls the trade-off between maximizing margin and minimizing training errors. Tests values [0.1, 1, 10, 100] to find optimal balance between underfitting and overfitting.
Gamma (Kernel coefficient) – Defines the influence reach of training examples. Tests ['scale', 'auto', 0.01, 0.1, 1] to determine optimal decision boundary complexity.
Kernel type – Uses RBF (Radial Basis Function) kernel for capturing non-linear patterns in medical data.


3. Cross-Validation for Robust Evaluation: 



Use 5-fold cross-validation where training data is divided into 5 subsets, and each parameter combination is trained and validated 5 times with different data splits. 
This ensures that the selected hyperparameters generalize well across different data samples rather than just fitting one particular train-validation split.


4. Model Training and Evaluation



Train the final SVM model using the best hyperparameters discovered through grid search
Apply the optimized model to predict diabetes outcomes on unseen test data
Evaluate performance using comprehensive metrics: confusion matrix, classification report, accuracy, precision, recall, and F1-score


5. Performance Comparison and Interpretation



Compare the tuned model's performance against the baseline model to assess the improvement achieved through hyperparameter optimization. Key aspects to analyze include accuracy gains, precision-recall trade-offs, and changes in confusion matrix patterns.
This comprehensive approach demonstrates the importance of systematic parameter optimization in building reliable medical diagnostic systems that can assist healthcare professionals in clinical decision-making.


CSV File Structure



﻿



Sample Data



Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,FamilyHistory,HbA1c,Outcome

148,72,35,0,33.6,0.627,50,0,11,1

85,66,29,0,26.6,0.351,31,0,5,0

183,64,0,0,23.3,0.672,32,1,11,1

89,66,23,94,28.1,0.167,21,1,5,0

137,40,35,168,43.1,2.288,33,0,8,1

Input format :
CSV File Input:

The program prompts the user to enter the name of the CSV file containing diabetes patient data.
Input must include the file extension .csv.
Output format :
The program produces evaluation outputs for the hyperparameter-tuned model:



1. Confusion Matrix:



Prints the heading: Confusion Matrix
Displays a 2×2 matrix showing the classification results:
[[TN FP]

[FN TP]]

Where:
TN (True Negative) = Correctly predicted as "No Diabetes" (class 0)
FP (False Positive) = Incorrectly predicted as "Has Diabetes" (class 1) when actually "No Diabetes"
FN (False Negative) = Incorrectly predicted as "No Diabetes" when actually "Has Diabetes"
TP (True Positive) = Correctly predicted as "Has Diabetes" (class 1)
Followed by: =================== (separator line)
Followed by a blank line


2. Classification Report:



Prints the heading: Classification Report:
Displays a detailed classification report showing:


Per-class metrics (for class 0 and class 1):
precision – Ratio of correct positive predictions to total positive predictions
recall – Ratio of correct positive predictions to total actual positives
f1-score – Harmonic mean of precision and recall
support – Number of actual occurrences of each class in the test set


Overall metrics:
accuracy – Overall correctness of predictions
macro avg – Unweighted average of per-class metrics
weighted avg – Weighted average of per-class metrics (weighted by support)


Format includes proper column alignment with default sklearn decimal formatting
Followed by: =================== (separator line)


3. Individual Metrics:



Four individual metrics, each on a separate line:
accuracy: X.XXX – Overall accuracy score (3 decimal places)
recall: X.XXX – Recall score for class 1 (3 decimal places)
f1-score: X.XXX – F1-score for class 1 (3 decimal places)
precision: X.XXX – Precision score for class 1 (3 decimal places)
All metrics are displayed with exactly 3 decimal places
Format: metric_name: value (lowercase metric name, colon, space, value)


Note: The output contains NO intermediate printing during data loading, preprocessing, scaling, splitting, or grid search. Only the final evaluation metrics for the tuned model are displayed.



Refer to the sample output for formatting specifications.

Code constraints :
CSV File Constraints:



Must be a .csv file in the same directory as main.py and ML_Modules.py.
Must contain columns: Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, FamilyHistory, HbA1c, Outcome
Outcome must be binary (0 or 1).


Features for Modeling



Use: Glucose, BMI, Age, FamilyHistory, HbA1c
Target: Outcome
Remove rows where Glucose = 0 or BMI = 0


Data Processing



Outlier treatment: IQR winsorization (threshold 1.5) on features only.
Scale features using StandardScaler.
Split data: 80% train, 20% test (random_state=42).


Hyperparameter Tuning



Parameter grid:
C: [0.1, 1, 10, 100]
gamma: ['scale', 'auto', 0.01, 0.1, 1]
kernel: ['rbf']
GridSearchCV: cv=5, scoring='accuracy', n_jobs=-1.
Select best_estimator_ for predictions.


Evaluation



Use evaluate_classifier(y_test, y_pred) for:
Confusion matrix
Classification report
Accuracy, recall, precision, F1-score (3 decimals)
No intermediate prints during preprocessing, scaling, splitting, or grid search.
Sample test cases :
Input 1 :
Sample.csv
Output 1 :
Confusion Matrix
[[2 3]
 [1 4]]
===================

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.40      0.50         5
           1       0.57      0.80      0.67         5

    accuracy                           0.60        10
   macro avg       0.62      0.60      0.58        10
weighted avg       0.62      0.60      0.58        10

===================
accuracy: 0.600
recall: 0.800
f1-score: 0.667
precision: 0.571